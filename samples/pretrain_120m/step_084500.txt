Samples generated with tokenizer=tokenizer/tokenizer.json
precision=bf16, temperature=0.7, top_p=0.9, top_k=0, max_new_tokens=256, min_new_tokens=32, greedy=False
================================================================================
[Prompt 1] (prompt_tokens=8)
Once upon a time, 

[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[72, 10381, 7506, 8742, 3063, 15639, 3794, 1152, 4194, 9200]
first_step_topk_probs=[0.038666777312755585, 0.009689592756330967, 0.009266531094908714, 0.008861947804689407, 0.008104996755719185, 0.008104996755719185, 0.007751127239316702, 0.005929742474108934, 0.005929742474108934, 0.005670845974236727]

[New tokens 1] count=234 first30=[11025, 566, 3286, 17, 722, 410, 261, 1040, 3556, 286, 11740, 1411, 688, 1593, 3895, 574, 3566, 289, 2522, 17, 1516, 979, 345, 2220, 2721, 290, 266, 4326, 349, 566]
[Full output 1]
 Once upon a time, aimed his mother. He was a very smart and intelligent three year old boy who loved to explore. One day he went outside in the garden with his best friend. They were playing tag when they saw a bright yellow flower. The little boy thought it looked so pretty that he wanted to pick it. His friend said no, but the little boy kept looking at the flower. Suddenly, his mother came out of the house and said "Let's go inside now". The little boy didn't want to leave, but he knew his mom was right. So, he slowly put the flower back where he found it. Then, he and his friend went inside for lunch. The little girl asked him why he had left the flower behind. He told her all about how he had picked it. She smiled and said she was proud of him. After lunch, the little boy went outside again. He wanted to pick some more flowers, but this time he remembered what his mother had said: be kind and polite. He decided to be kind and give them away. As soon as he did, he felt happy knowing that he had done something good by picking the flower.

================================================================================
[Prompt 2] (prompt_tokens=11)
In a distant future, humans and robots 

[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[72, 7506, 8742, 10381, 3063, 1152, 15639, 3794, 6440, 9200]
first_step_topk_probs=[0.05458741635084152, 0.020443396642804146, 0.009153060615062714, 0.006404147483408451, 0.005857131443917751, 0.005356839392334223, 0.004480808041989803, 0.004098075907677412, 0.004098075907677412, 0.0039191474206745625]

[New tokens 2] count=243 first30=[7506, 292, 266, 1884, 289, 1786, 430, 2026, 539, 37, 877, 483, 5, 4, 447, 3095, 962, 544, 3851, 15, 652, 584, 1299, 3566, 289, 601, 524, 286, 2522, 17]
[Full output 2]
 In a distant future, humans and robots ints of the popular toaster's called "Beware"! Named after her father, she had always loved to go out and explore. She decided to go for a walk in the woods near her home. As she was walking through the trees, she saw something amazing: a beautiful butterfly! It was so colorful with its bright colors and it was flying around. Ned was mesmerized by the beauty of nature. Suddenly, Ned noticed a small patch of grass that seemed to be hiding behind some bushes. She quickly ran over to investigate. When she got there, she found that it was surrounded by little green plants. The plants were surrounded by delicious fruit, which made Ned feel happy and excited. She watched as the plants grew bigger and bigger until they had grown into tall plants. After a while, Ned continued on her walk and came across an old lady who smiled at her. The old lady said, "Hello there! I see you like this garden. You are very special. This is a gift from my grandmother." Ned thanked the old lady and continued on her way. From then on, she was sure to visit the flower patch every time she went outside.

================================================================================
[Prompt 3] (prompt_tokens=12)
The following is a news report:




[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[72, 7506, 8742, 10381, 15639, 3063, 1152, 10257, 10083, 12007]
first_step_topk_probs=[0.018666913732886314, 0.013060731813311577, 0.00639377161860466, 0.00611460953950882, 0.005348160397261381, 0.005348160397261381, 0.005348160397261381, 0.004891342017799616, 0.00427822582423687, 0.00427822582423687]

[New tokens 3] count=256 first30=[6782, 6782, 6782, 414, 539, 36, 688, 2849, 15, 266, 2684, 292, 266, 8709, 672, 322, 3648, 1491, 836, 266, 3782, 3236, 9094, 6734, 17, 539, 7676, 266, 10296, 504]
[Full output 3]
 The following is a news report:


373737 - "A year ago, the effects of the Fed would be greater," said the International Monetary Fund. "As the dollar has grown in recent years, the interest rates are higher than the end of the last century." But what about the inflation rate? The Fed's gross domestic product price is the lowest in 20 years, and that it could cost anywhere from $100 to $2 billion. It is worth noting that the market has been struggling for more than 10 years. In June, the US economy has doubled in over half its GDP since 2011, which is nearly two-thirds of the country's GDP since 2007. The first-ever bond market was at $2.5 trillion (US$3.8 trillion) in the second quarter of 2011. The second-largest U.S. market is $1.9 trillion. That is the highest in the second-largest United States. The second stage of the last recession is in the fourth-est month of fiscal 2011. The Bank of America is currently expanding its shares with a new tax base on U.S.-based products, including the U.S., American Express and American Express. U.S.'s foreign exchange shares have fallen by almost 6 percent in December 2012 compared to

================================================================================
[Prompt 4] (prompt_tokens=14)
Neural networks are a class of machine learning models that 

[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[72, 7506, 10257, 15896, 15639, 676, 10083, 8742, 9200, 10381]
first_step_topk_probs=[0.05357956141233444, 0.025084229186177254, 0.010271590203046799, 0.005748990457504988, 0.005497985985130072, 0.005497985985130072, 0.004598867613822222, 0.004398078192025423, 0.004206051118671894, 0.004206051118671894]

[New tokens 4] count=256 first30=[23543, 332, 361, 2996, 2565, 321, 266, 2094, 292, 4119, 415, 19759, 17, 1009, 504, 660, 1613, 329, 261, 1207, 290, 6044, 15, 5435, 286, 8750, 321, 859, 963, 286]
[Full output 4]
 Neural networks are a class of machine learning models that  Monica is an amazing model for the University of California at Berkeley. She has been working on a project in Chicago, England and Georgia for many years and has been working with SXSW as an Assistant Professor in Philosophy and Psychology from Philadelphia College of Medicine and the University of Michigan. Her first book was “Midnight” by R.S. Lewis. A graduate student at UC Berkeley, she taught at Stanford University in Chicago, which is now an assistant professor in International Studies, The & Ithaca College of Medicine in and in the School of Visual Arts. Her second book was “The Biggest Art of Music,” by Maureen Davis. The book was “A New York.” It is a book about the art of music and how it can be influenced by the likes of a lot of people around the world and how they work. I loved the opportunity to read it because it was so fun to learn about this new world! I would like to thank you for your support. The work you did during your time here was fantastic. Your visit to my hometown in San Francisco was spectacular. You see the city and how the people were doing, they were making music and everyone was having such great conversations. You’ve never seen anything like it before. It

================================================================================
[Prompt 5] (prompt_tokens=21)
Here is a short Python snippet:

def fib(n):
    

[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[7506, 72, 15639, 10381, 10257, 1541, 3063, 22045, 8742, 9200]
first_step_topk_probs=[0.024695592001080513, 0.013218598440289497, 0.01011245884001255, 0.00884488970041275, 0.007736199535429478, 0.005176477134227753, 0.005176477134227753, 0.004527620039880276, 0.004527620039880276, 0.004329941235482693]

[New tokens 5] count=256 first30=[10933, 338, 266, 1276, 292, 376, 371, 771, 16, 28550, 541, 266, 1518, 286, 1776, 292, 266, 745, 17, 1217, 266, 629, 4169, 15, 266, 2035, 290, 2682, 3085, 504]
[Full output 5]
 Here is a short Python snippet:

def fib(n):
     observe that the rest of us are well-informed about the past and future of the people. To the new century, the growth in economic activity has been driven by the growing popularity of the American economy. The trend has since changed for years from one to four decades ago, when the developed world was no longer around than in the 1930s. The economic growth in the late 1960s had changed considerably. In 1980, the economic growth in America increased at about 10 percent in the 1990s, but with the loss of $11.3 billion. This year the economic growth now declined, and the growth in the 1970s began to be slightly less significant. In 2009, the U.S. government had proposed to implement economic reforms aimed at boosting production, but it would not take into account the long-term effects on population growth. In 2013, the economy moved down from one-fourth of the total GDP. With the rise of almost 2 million people, the unemployment rate rose by 9.5 percent in 2010, up from just 1.2 percent last fall. The economic recovery continued as expected, and this year the inflation has been lower. It has also started to expand to more than 2.7 million households across the country, including two half-seven

================================================================================
