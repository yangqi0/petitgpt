Samples generated with tokenizer=tokenizer/tokenizer.json
precision=bf16, temperature=0.6, top_p=0.85, top_k=0, max_new_tokens=256, min_new_tokens=32, greedy=False
================================================================================
[Prompt 1] (prompt_tokens=8)
Once upon a time, 

[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[72, 16862, 16685, 15208, 27514, 3056, 31645, 19628, 25984, 21955]
first_step_topk_probs=[0.04328736290335655, 0.02317005582153797, 0.020877933129668236, 0.020877933129668236, 0.015274622477591038, 0.010069658048450947, 0.009073523804545403, 0.008175923489034176, 0.008175923489034176, 0.005981634370982647]

[New tokens 1] count=256 first30=[983, 264, 16, 13882, 9120, 645, 4437, 415, 266, 1320, 2826, 350, 266, 10572, 17, 351, 814, 592, 410, 1073, 290, 896, 5819, 446, 4303, 333, 17, 377, 2890, 1028]
[Full output 1]
 Once upon a time, ometre-shaped rocks were discovered at the same location as the Moon. The first one was found in 1929 by William C. Hancock and his team of scientists who had been working on the Moon for more than a year before.
The discovery was made by the British Geological Survey (BGS) in 1969. It was discovered that the moon is not a single object but a giant planet. The moon is believed to be between about 3 and 5 million years old.
The Moon's orbit around the Sun was determined by the gravitational effect of gravity. The gravitational force was used to determine the position of the Moon in relation to the Sun, which was then separated from its own body by a gravitational field called the orbit.
The orbit was then determined by the gravity of the Earth, which was known as the Moon's orbit.
In 1931, the US government announced that the Moon was too close to the Sun to support life. In addition, the Moon was also thought to be far closer to the Sun than it was to the Moon itself.
The lunar orbit was later confirmed by the US Space Agency.
In 2004, the US NASA project was launched into the International Space Station (ISS) and later the Moon was placed under the command

================================================================================
[Prompt 2] (prompt_tokens=11)
In a distant future, humans and robots 

[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[72, 16685, 27514, 16862, 25984, 9343, 15208, 19628, 2400, 18590]
first_step_topk_probs=[0.05144646018743515, 0.04635706543922424, 0.014739657752215862, 0.014739657752215862, 0.011967656202614307, 0.009716968983411789, 0.009716968983411789, 0.0064058247953653336, 0.005201123654842377, 0.005201123654842377]

[New tokens 2] count=256 first30=[22800, 2803, 3412, 289, 700, 266, 897, 292, 604, 918, 17, 583, 332, 694, 4421, 290, 266, 2161, 1657, 292, 604, 16018, 574, 645, 6848, 321, 266, 1011, 3637, 17]
[Full output 2]
 In a distant future, humans and robots  unsuccessfully tried to make the world of our own. This is what happened in the early days of our ancestors who were searching for the right answer.
The search for the right answers was a time when humans had been living with their own bodies, but they weren't really interested in finding the right answer to that question. They simply didn't know how to use the information they needed to make an answer. Instead, they had to learn something about their own body type and how it could be used to make a decision on whether or not to move.
As a result, humans were able to create an alternative to using their own bodies to make decisions. The problem was that many people believed that humans were more intelligent than most other people, so they thought it was more likely that some kind of intelligent person would be better suited to help them.
Both theories were wrong; they simply failed to explain why people were more intelligent, so they just ignored the fact that humans were very much like other people. But because we do know that humans are more intelligent than other people, we also have a higher probability that humans can be more intelligent than others.
This suggests that humans are the same as us (and we don't know which one we're talking about). We

================================================================================
[Prompt 3] (prompt_tokens=12)
The following is a news report:




[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[16685, 16862, 72, 3056, 25984, 27514, 9343, 30275, 15896, 17619]
first_step_topk_probs=[0.0320131853222847, 0.02884630300104618, 0.01901666820049286, 0.010178889147937298, 0.007447034120559692, 0.007447034120559692, 0.007447034120559692, 0.003986109979450703, 0.003986109979450703, 0.003591779852285981]

[New tokens 3] count=204 first30=[27820, 15, 570, 1824, 350, 266, 814, 3589, 292, 266, 1257, 5204, 15, 410, 5862, 289, 266, 2263, 2666, 290, 1812, 13304, 17, 494, 338, 688, 15, 266, 5203, 286]
[Full output 3]
 The following is a news report:


 tempeh, also known as the first round of the food chain, was introduced to the United States in 1882. In that year, the Food and Drug Administration (FDA) approved the product for use in the United States.

The product was also marketed by the company Paxil, which manufactured it in the early 1930s. It was not until the late 1940s that the term "Paxil" became widely used in the United Kingdom and Japan.

Sources

1918 births
Living people
People from Stoke-on-Trent, New York
American food manufacturers
United States Food and Drug Agency employees
People from Croydon, Connecticut
United States Department of Agriculture workers
United States Army personnel of World War II
World War I officers
Washington State Department of Health
United States Navy personnel of World Wars I
Recipients of the Order of Merit
Women of the Order
Knights Commander of the Order

================================================================================
[Prompt 4] (prompt_tokens=14)
Neural networks are a class of machine learning models that 

[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[72, 16685, 27514, 16862, 3056, 15208, 25984, 2400, 15896, 9343]
first_step_topk_probs=[0.1040160059928894, 0.05567575991153717, 0.019646061584353447, 0.00947551243007183, 0.007693515624850988, 0.007693515624850988, 0.006246646866202354, 0.0056286961771547794, 0.0056286961771547794, 0.0050718761049211025]

[New tokens 4] count=256 first30=[13953, 286, 14699, 202, 1414, 813, 2048, 2088, 292, 14699, 332, 266, 13953, 17, 351, 13953, 371, 3178, 935, 445, 3026, 15, 2437, 15, 5259, 369, 5259, 18853, 664, 266]
[Full output 4]
 Neural networks are a class of machine learning models that  costumes and costume
The most common type of costume is the costumes. The costumes are usually made from wood, paper, fabric or fabric woven into the shape of a tree trunk. These costumes are often made from cotton, cotton or silk. They may also be made from wool or leather.
A typical costume is the dress of a woman. There are many different styles for different kinds of clothing including:
- Busted dresses - this is called "mud dress" and it can be worn by women who wear them.
- Black and white dresses - these are made from wool, linen or other materials.
- Pink and black dresses - these were made from silk and cotton.
- Blue and red dresses - these could be used to make the dress more attractive to men.
- Woven dresses - these would be made from cloth.
- White dresses - these might be made from cotton.
Some people use various forms of costume in their life such as the "Mudie" (soldier) dress or the "Wavig" (women's dress). Some people do not have the right to wear a dress if they want to be considered beautiful.
During the Renaissance, there was a time when many people wore

================================================================================
[Prompt 5] (prompt_tokens=21)
Here is a short Python snippet:

def fib(n):
    

[Debug]
bos_id=2 eos_id=3
first_step_eos_prob=0.000e+00
first_step_topk_ids=[72, 16685, 16862, 15208, 27514, 9343, 15896, 3056, 17619, 25984]
first_step_topk_probs=[0.12461943924427032, 0.08215409517288208, 0.026121653616428375, 0.017220431938767433, 0.011352417059242725, 0.008305605500936508, 0.008305605500936508, 0.006743625272065401, 0.006076510529965162, 0.006076510529965162]

[New tokens 5] count=256 first30=[29086, 66, 3607, 1282, 539, 37, 3598, 5, 202, 321, 1646, 290, 1792, 11, 81, 2773, 1582, 2088, 29, 10966, 202, 681, 313, 7643, 1499, 29, 1582, 224, 14035, 202]
[Full output 5]
 Here is a short Python snippet:

def fib(n):
     custard_name = "Baby"
 for i in range(n): # type: ignore
 if n == 0: #  recy
 return
 else: # 
 return

# ç¾©è½¬å§‹
class GenoCurrent(HyperText.ABC):
 """
 å®å§‹æ•°
 """

 def __init__(self, *args, **kwargs):
 self.hidden = True
 self.ridden = False
 self.parent = None
 self.font = None

 def _repr(self) -> bool:
 """
 :param self: ç›®æŸ¥å–åˆ†çº¿
 :type self: å­˜æŸ¥
 :return:
 """ """
 return self._repr(*args, *arg)

 @property
 def name(self)(self)():
 return self

 @name.setter
 def name_with_or_not_found(self, name):
 """"""

 if not self._hex(self.hex) or self.he

================================================================================
