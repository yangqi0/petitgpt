Samples generated with tokenizer=tokenizer/tokenizer.json
precision=bf16, temperature=0.7, top_p=0.9, top_k=0, max_new_tokens=128, min_new_tokens=0, greedy=False
================================================================================
[Prompt 1] (prompt_tokens=8)
Once upon a time, 

[Debug]
bos_id=[BOS] eos_id=[EOS]
first_step_eos_prob=0.49442434310913086
first_step_topk_ids=[3, 2, 261, 410, 289, 266, 554, 17, 2895, 15]
first_step_topk_probs=[0.49442434310913086, 0.34593525528907776, 0.009726196527481079, 0.004553492646664381, 0.0009980390314012766, 0.00046724980347789824, 0.00039083766750991344, 0.0003822103317361325, 0.00036552263190969825, 0.00034184727701358497]

[New tokens 1] count=1 first30=[3]
[New text 1] repr=''

[Full output 1]
 Once upon a time, 

================================================================================
[Prompt 2] (prompt_tokens=11)
In a distant future, humans and robots 

[Debug]
bos_id=[BOS] eos_id=[EOS]
first_step_eos_prob=0.19482272863388062
first_step_topk_ids=[2, 3, 289, 410, 17, 261, 15, 266, 2895, 286]
first_step_topk_probs=[0.6219155192375183, 0.19482272863388062, 0.012234166264533997, 0.004790968261659145, 0.003065785625949502, 0.0023453785106539726, 0.002006108406931162, 0.0013127046404406428, 0.0008214696426875889, 0.0005256660515442491]

[New tokens 2] count=128 first30=[1687, 17, 1009, 410, 4730, 17, 351, 13007, 17, 351, 18209, 17, 1009, 28764, 349, 261, 17, 722, 410, 261, 17, 722, 410, 261, 11755, 17, 21378, 17, 901, 1471]
[New text 2] repr=" mom. She waspa. Theerge. Theangered. Sheprotein with a. He was a. He was a expense. magnesium. They ' a mant, water. She was a Vista. He was. He wasuf. She to. The. He wanted to. pain. He is the. She Sus. He. She the the pickup. He Module to the. She was ayles. She a little girl. She Best. They say to the. They done. They hop. He. Shelan. They had the, the. She. He into. She, the and the trusted. They. They"

[Full output 2]
 In a distant future, humans and robots  mom. She waspa. Theerge. Theangered. Sheprotein with a. He was a. He was a expense. magnesium. They ' a mant, water. She was a Vista. He was. He wasuf. She to. The. He wanted to. pain. He is the. She Sus. He. She the the pickup. He Module to the. She was ayles. She a little girl. She Best. They say to the. They done. They hop. He. Shelan. They had the, the. She. He into. She, the and the trusted. They. They

================================================================================
[Prompt 3] (prompt_tokens=11)
The following is a news report:



[Debug]
bos_id=[BOS] eos_id=[EOS]
first_step_eos_prob=0.12237425148487091
first_step_topk_ids=[2, 3, 289, 261, 266, 410, 17, 15, 414, 292]
first_step_topk_probs=[0.6979557275772095, 0.12237425148487091, 0.014356839470565319, 0.008402357809245586, 0.0032904103863984346, 0.0031467473600059748, 0.001260099932551384, 0.0006744829588569701, 0.0003301874385215342, 0.00028879925957880914]

[New tokens 3] count=1 first30=[3]
[New text 3] repr=''

[Full output 3]
 The following is a news report:



================================================================================
[Prompt 4] (prompt_tokens=14)
Neural networks are a class of machine learning models that 

[Debug]
bos_id=[BOS] eos_id=[EOS]
first_step_eos_prob=0.19203302264213562
first_step_topk_ids=[2, 3, 261, 266, 289, 410, 17, 338, 286, 414]
first_step_topk_probs=[0.6130101680755615, 0.19203302264213562, 0.010086910799145699, 0.008437339216470718, 0.00472236517816782, 0.0013529802672564983, 0.0011067379964515567, 0.0006194395245984197, 0.0005540240672416985, 0.0005540240672416985]

[New tokens 4] count=42 first30=[2, 2, 261, 261, 261, 286, 286, 261, 4441, 289, 266, 354, 1127, 286, 532, 17, 351, 17, 9471, 410, 266, 25529, 17, 722, 410, 261, 1576, 290, 266, 15]
[New text 4] repr=' a a a and and a leaving to the itted and cl. The. Everyone was theoder. He was a big in the, and a. MAX and their. The a Mick.'

[Full output 4]
 Neural networks are a class of machine learning models that  a a a and and a leaving to the itted and cl. The. Everyone was theoder. He was a big in the, and a. MAX and their. The a Mick.

================================================================================
[Prompt 5] (prompt_tokens=21)
Here is a short Python snippet:

def fib(n):
    

[Debug]
bos_id=[BOS] eos_id=[EOS]
first_step_eos_prob=0.40264809131622314
first_step_topk_ids=[2, 3, 289, 261, 266, 292, 17, 15, 338, 351]
first_step_topk_probs=[0.4402526915073395, 0.40264809131622314, 0.005541960708796978, 0.0016977647319436073, 0.0014849546132609248, 0.0007948388811200857, 0.0006648542475886643, 0.0006358262617141008, 0.0006217907648533583, 0.0005561269354075193]

[New tokens 5] count=56 first30=[2, 12298, 15, 266, 4643, 15, 261, 3651, 17, 351, 17, 351, 6935, 15, 286, 266, 266, 1654, 261, 1576, 289, 266, 266, 1508, 742, 286, 266, 365, 8565, 15]
[New text 5] repr=" possession, the joy, a pieces. The. The chest, and the the Do a big to the the little't and theist:||,. The,. The. Early. The movie. The a experts. The kind. The to the squash. He."

[Full output 5]
 Here is a short Python snippet:

def fib(n):
     possession, the joy, a pieces. The. The chest, and the the Do a big to the the little't and theist:||,. The,. The. Early. The movie. The a experts. The kind. The to the squash. He.

